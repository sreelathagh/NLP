{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"IOyVhefrcbd2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from tqdm import tqdm"],"metadata":{"id":"vC3I-iOytFE1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"id":"lMf-SfqMVESp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HVa8k1eys1-P"},"outputs":[],"source":["#1 Use torch.randn to create two tensors of size (29, 30, 32) and (32, 100) .\n","a = torch.randn(29, 30, 32)\n","b = torch.randn(32,100)\n","a.shape, b.shape"]},{"cell_type":"code","source":["# 2 Use torch.matmul to matrix multiply the two tensors.\n","torch.matmul\n","print(\"torch.matmul\")\n","c = torch.matmul(a,b)\n","print(c.size())\n","# 4 Use torch.sum on the resulting tensor, passing the optional argument of dim=1 to sum across the 1st dimension. Before you run this, can you predict the size?\n","d = torch.sum(c, dim=1) #dim=1 is sum across the rows of matrix\n","d.size()\n","\n","torch.mm\n","print(\"torch.mm\")\n","mat_1 = torch.tensor([[1, 2, 3],\n","                      [4, 3, 8],\n","                      [1, 7, 2]])\n","  \n","mat_2 = torch.tensor([[2, 4, 1],\n","                      [1, 3, 6],\n","                      [2, 6, 5]])\n","c = torch.mm(mat_1, mat_2,out=None)\n","print(c.size())\n","d = torch.sum(c, dim=1) #dim=1 is sum across the rows of matrix\n","d.size()\n","\n","torch.bmm\n","print(\"torch.bmm\")\n","mat_1 = torch.randn(2, 3, 3)\n","mat_2 = torch.randn(2, 3, 4)\n","c = torch.bmm(mat_1, mat_2) #in batched matrix-matrix multiplication bmm(input, batch2,*) batch2 must be a 3d-tensor\n","print(c.size())\n","d = torch.sum(c, dim=1) #dim=1 is sum across the rows of matrix\n","d.size()\n","\n","#torch.einsum\n","print(\"torch.einsum\")\n","c = torch.einsum('ii',torch.randn(3,3))\n","c\n","\n","torch.matmul\n","print(\"torch.matmul\")\n","c = torch.matmul(a,b)\n","print(c.size())\n","# 4 Use torch.sum on the resulting tensor, passing the optional argument of dim=1 to sum across the 1st dimension. Before you run this, can you predict the size?\n","d = torch.sum(c, dim=1) #dim=1 is sum across the rows of matrix\n","d.size()\n","\n"],"metadata":{"id":"8lgWGJRMHLsl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3 What is the difference between torch.matmul , torch.mm , torch.bmm , and torch.einsum , and the @ operator?**\n","\n","**torch.mm:**\n","torch.mm computes matrix multiplication by taking an m×n Tensor and an n×p Tensor. It can deal with only two-dimensional matrices and not with single-dimensional ones. This function does not support broadcasting. Broadcasting is nothing but the way the Tensors are treated when their shapes are different. The smaller Tensor is broadcasted to suit the shape of the wider or larger Tensor for operations.\n","\n","**torch.bmm:**\n","This method provides batched matrix multiplication for the cases where both the matrices to be multiplied are of only 3-Dimensions (x×y×z) and the first dimension (x) of both the matrices must be same. This does not support broadcasting. The “deterministic” parameter takes up boolean value. A ‘false‘ does a faster calculation which is non-deterministic. A ‘true‘ does a slower calculation however, it is deterministic.\n","\n","**torch.matmul:**\n","This method allows the computation of multiplication of two vector matrices (single-dimensional matrices), 2D matrices and mixed ones also. This method also supports broadcasting and batch operations. Depending upon the input matrices dimensions, the operation to be done is decided. The general syntax is given below.\n","\n","**torch.einsum:**\n","Sums the product of the elements of the input operands along dimensions specified using a notation based on the Einstein summation convention.\n","\n","**@operator:**\n","The @ – Simon H operator, when applied on matrices performs multiplication element-wise on 1D matrices and normal matrix multiplication on 2D matrices. If both the matrices have the same dimension, then the matrix multiplication is carried out normally without any broadcasting/prepending.  If any one of the matrices is of a different dimension, then appropriate broadcasting is carried out first and then the multiplication is carried out. This operator applies to N-Dimensional matrices also.\n"],"metadata":{"id":"cD4NYuuqbC8K"}},{"cell_type":"code","source":["#5 Create a new long tensor of size (3, 10).\n","x = torch.ones(3,10, dtype=torch.int64)\n","\n","#6 Use this new long tensor to index into the tensor from step 2.\n","y=c[x]\n","y.shape\n","torch.equal(y[0][0], y[1][1])"],"metadata":{"id":"Z4R2wuIrKKgx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#7 Use torch.mean to average across the last dimension in the tensor from step 6.\n","torch.mean(c[x], dim=3), torch.mean(c[x], dim=3).shape"],"metadata":{"id":"2Drry93ychAK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Write a pure PyTorch program to compute the value of √2 up to 4 decimal places without using the square root or other math functions from any of the libraries.\n","def squareroot(x):\n","    re = x\n","    precision = 10 ** (-10)\n","    while abs(x - re * re) > precision:\n","        re = (re + x / re) / 2\n","        a = torch.tensor(re, dtype=torch.float16)\n","        a= a.item()\n","    return round(a,4)\n","\n","squareroot(4)"],"metadata":{"id":"YtdwQSNeLP6p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Fail-fast exercises"],"metadata":{"id":"FzQZGAxiewHD"}},{"cell_type":"code","source":["#Importing all the libs\n","import os\n","import urllib\n","import zipfile\n","import pandas as pd\n","import torch.nn as nn\n","from keras.preprocessing.text import Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","import random"],"metadata":{"id":"cqJnkpyUBrkn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#downloading and extracting Glove embeddings\n","glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n","glove_dir = os.path.join(os.path.curdir, \"glove\")\n","if not os.path.exists(os.path.join(os.path.curdir, \"glove\", \"glove.6B.300d.txt\")):\n","    zip_path, _ = urllib.request.urlretrieve(glove_url)\n","    with zipfile.ZipFile(zip_path, \"r\") as f:\n","        f.extractall(glove_dir)\n","\n","#Creating the Glove embedding dictionary\n","embeddings_dict = {}\n","with open(\"/content/glove/glove.6B.300d.txt\", 'r') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        vector = np.asarray(values[1:], \"float32\")\n","        embeddings_dict[word] = vector"],"metadata":{"id":"oRbAcdOIaW8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Some hyperparameters\n","batch_size = 32\n","num_features = 5000\n","embedding_size = 16\n","max_len = 50"],"metadata":{"id":"r7ofqOPGEVje"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#IMDB data frame considered only first 512 columns of data\n","df = pd.read_csv(\"/content/drive/MyDrive/NLP243/243_HW1/data/hw1_train-1.csv\")\n","df=df.head(512)"],"metadata":{"id":"L42Rtni0E_2v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class data_embd(Dataset):\n","  def __init__(self, data: pd.DataFrame, embeddings_dict, max_len):\n","    self.data = data\n","    self.embds = embeddings_dict\n","    self.default =  self.embds['the']\n","    self.glove_dim = 300\n","    self.max_len = max_len\n","\n","  def tokenize(self, text: str):\n","    return [i for i in text.split()]\n","\n","  def encode_tokens(self, tokens):\n","    encoded = [torch.tensor(embeddings_dict.get(token, self.default)) for token in tokens]\n","    encoded += [torch.zeros(self.glove_dim) for _ in range(self.max_len-len(tokens))]\n","    return encoded\n","  \n","  def __getitem__(self, n: int):\n","    textstr = self.data['textstr '].iloc[n]\n","    return self.encode_tokens(self.tokenize(textstr))\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","\n","df_a = data_embd(df, embeddings_dict, max_len=max_len)\n","train_loader = DataLoader(df_a, batch_size=512, shuffle=False)"],"metadata":{"id":"o2sx0m3gsMhh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#question1, question3\n","class DeepAveragingNetwork(nn.Module):\n","  def __init__(self, max_len):\n","    super().__init__()\n","    self.max_len=max_len\n","    self.glove_dim = 300\n","    # self.glove = GloVe(name='6B', dim=glove_dim)\n","\n","  def forward(self,embeddings):\n","    ems = [embeddings[i] for i in range(0, len(embeddings))]\n","    deepavg = torch.mean(torch.stack(ems), dim=0)\n","    return deepavg\n","    \n","model = DeepAveragingNetwork(max_len).to(device)\n","pbar = tqdm(train_loader)\n","for embds in pbar:\n","  op = model(tuple(embds))\n","print(\"\\nfinal shape when 512 sentences are inferences on GPU\",op.shape)"],"metadata":{"id":"1sm5ZjJzF7Qq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#question2\n","#using sci-kit libraries for dimensionality reduction using PCA(principle component Analysis)\n","from sklearn.decomposition import PCA\n","# Initializing PCA object with number of components as (50)\n","pca = PCA(n_components=50)\n","# Fitting the PCA model to data from deep average network\n","pca.fit(op)\n","# Applying tranform method for dimensionality reduction of the data\n","reduced_data = pca.transform(op)\n","# reduced_data.shape\n","\n","print(f'original dimensions of the data: {op.shape} | After PCA: {reduced_data.shape}')"],"metadata":{"id":"xRhoQuV0X0qx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#question4\n","class MutliEmbedding(nn.Module):\n","  def __init__(self,num_emb:int, size_emb1:int, size_emb2:int):\n","    super(MutliEmbedding, self).__init__()\n","    self.num_emb = num_emb\n","    self.indices1 = size_emb1\n","    self.indices2 = size_emb2\n","\n","  def forward(self,ind1,ind2):\n","    op = torch.cat((ind1,ind2),1).unsqueeze(0)\n","    return op\n","    \n","\n","num_emb =1\n","size_emb1=300\n","size_emb2=300\n","multiemb = MutliEmbedding(num_emb, size_emb1, size_emb2)\n","indices1= torch.tensor(embeddings_dict['green']).unsqueeze(0)\n","indices2= torch.tensor(embeddings_dict['apple']).unsqueeze(0)\n","print(indices1.shape)\n","print(indices2.shape)\n","final=multiemb(indices1, indices2)\n","final.shape"],"metadata":{"id":"Wku0zSBoNuvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#question5\n","from collections import Counter\n","class DummySentenceLabelDataset(Dataset):\n","  def __init__(self, num_sentences, max_len):\n","    self.num_sentences = num_sentences\n","    self.max_len = max_len\n","    # self.default =  self.embds['the']\n","    self.vocab = ['the', 'in', 'who', 'cast', 'is', 'of', 'actor', 'movie', 'life', 'beautiful', \\\n","                  'for', 'played', 'and', 'crew', 'was', 'show', 'campaign', 'on', 'female', 'i', 'me', 'july', \\\n","                  'plays', 'star', 'find', 'man', 'starred', 'were', 'stars', 'what', 'actors', 'can', 'captain', 'america',\\\n","                  'credits', 'from', 'lead', 'charlie', 'are', 'see', 'list', 'rocky', 'members', 'apollo', \\\n","                  'thirteen', 'luke', 'wars', 'new', 'hope', 'godfather']\n","\n","    self.count = Counter(self.vocab)  \n","    self.tokens, self.counts = zip(*self.count.most_common(len(self.vocab)))\n","    self.embeddings_dict = {token: idx for idx, token in enumerate(self.tokens)}\n","    self.default = self.embeddings_dict['the']   \n","    \n","  def tokenize(self, text: str):\n","    return [i for i in text.split()]\n","\n","  def print_this(self):\n","    print(self.embeddings_dict)    \n","\n","  def encode_tokens(self, tokens):\n","    encoded = [torch.tensor([self.embeddings_dict.get(token, self.default)], dtype=torch.float32) for token in tokens]\n","    encoded += [torch.zeros(1) for _ in range(self.max_len-len(tokens))]\n","    return encoded\n","  \n","  def __getitem__(self, n:int):\n","    sentence = [random.choice(self.vocab) for _ in range(random.randint(1, self.max_len))]\n","    label = random.randint(0, 1)\n","    return self.encode_tokens(sentence), torch.tensor(float(label))\n","    \n","  def __len__(self):\n","    return self.num_sentences \n","\n","max_len = 20\n","model = DeepAveragingNetwork(max_len)\n","dataset = DummySentenceLabelDataset(num_sentences=10, max_len=max_len)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n","dataset.print_this()\n","\n","# let's measure the error rate for one epoch\n","error = 0.0\n","for sentence, label in (dataloader):\n","  print(sentence)\n","  prediction = model(sentence)\n","  error += abs(prediction - label)\n","print(f'error rate: {error/len(dataset)}')"],"metadata":{"id":"SNnAj4n7WILZ"},"execution_count":null,"outputs":[]}]}