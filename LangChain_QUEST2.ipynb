{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMr0x1kKbSzNYXAzbvH/zfu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreelathagh/NLP/blob/main/LangChain_QUEST2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws9Oq20mNPWs"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env OPENAI_API_KEY=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"
      ],
      "metadata": {
        "id": "AKrztyEkQNln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "mQNXrHFbVEQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample Example\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2,temperature=0.8, max_tokens=256)\n",
        "response=llm.generate([\"Tell me a joke.\"])\n",
        "response"
      ],
      "metadata": {
        "id": "1EcGI_QrVJXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question:4"
      ],
      "metadata": {
        "id": "La_z3nWr40ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "import openai\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2,temperature=0.7, max_tokens=1024)\n",
        "prompt_template_names=\"generate some sweet and unique 10 baby girl {names} from India?\"\n",
        "prompt = PromptTemplate(input_variables=[\"names\"], template=prompt_template_names)\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain_1 = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain_1.run('name'))"
      ],
      "metadata": {
        "id": "h7E3V5EWoyUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question:5"
      ],
      "metadata": {
        "id": "xgZuTbNl46yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2,temperature=0.5, max_tokens=1024)\n",
        "prompt_template_bio=\"Create a made up biography of {names} from {origin}\"\n",
        "prompt_2 = PromptTemplate(input_variables=[\"names\", \"origin\"], template=prompt_template_bio)\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
        "\n",
        "print(chain_2.run({\"names\":\"Aarya\",\"origin\":\"Greece\"}))\n"
      ],
      "metadata": {
        "id": "jZoBSUWZKpDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.base import Chain\n",
        "\n",
        "from typing import Dict, List\n",
        "\n",
        "\n",
        "class ConcatenateChain(Chain):\n",
        "    chain_1: LLMChain\n",
        "    chain_2: LLMChain\n",
        "\n",
        "    @property\n",
        "    def input_keys(self) -> List[str]:\n",
        "        # Union of the input keys of the two chains.\n",
        "        all_input_vars = set(self.chain_1.input_keys)\n",
        "        return list(all_input_vars)\n",
        "\n",
        "    @property\n",
        "    def output_keys(self) -> Dict[str, str]:\n",
        "        return ['concat_output']\n",
        "\n",
        "    # def _call(self, inputs1: List[str],  inputs2: Dict[str, str]) -> Dict[str, str]:\n",
        "    def _call(self, inputs1: List[str]) -> Dict[str, str]:      \n",
        "        output = self.chain_1.run(inputs1)\n",
        "        return {'concat_output': output }\n",
        "\n",
        "concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)\n",
        "concat_output = concat_chain.run(concat_chain)\n",
        "print(f\"Concatenated output:\\n{concat_output}\")\n"
      ],
      "metadata": {
        "id": "OWckNwNZEc6Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}