{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr0x1kKbSzNYXAzbvH/zfu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreelathagh/NLP/blob/main/LangChain_QUEST2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ws9Oq20mNPWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a166a4fc-e317-4d39-e0e4-3f6b45e6e798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.79-py3-none-any.whl (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.3/216.3 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.10.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.8/dist-packages (from langchain) (2.25.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from langchain) (8.1.0)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.21.6)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.4.46)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.8/dist-packages (from langchain) (6.0)\n",
            "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (4.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, marshmallow-enum, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.7 langchain-0.0.79 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 typing-inspect-0.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67620 sha256=db53256825486b264f7f624781e9a29373cfe6adecf744cd3329e9d1a19a84bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/47/99/8273a59fbd59c303e8ff175416d5c1c9c03a2e83ebf7525a99\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.5\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env OPENAI_API_KEY=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"
      ],
      "metadata": {
        "id": "AKrztyEkQNln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e688c108-afc8-4c82-cf41-613c412ef994"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "mQNXrHFbVEQo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample Example\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2,temperature=0.8, max_tokens=256)\n",
        "response=llm.generate([\"Tell me a joke.\"])\n",
        "response"
      ],
      "metadata": {
        "id": "1EcGI_QrVJXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1acf63d2-fe1d-4a1f-d9d8-72c1fe766e72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LLMResult(generations=[[Generation(text='\\n\\nQ: What did the fish say when it hit the wall?\\nA: Dam!', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text=\"\\n\\nQ: What did one paper clip say to the other?\\nA: I'm so glad we can stick together!\", generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'total_tokens': 51, 'prompt_tokens': 5, 'completion_tokens': 46}})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question:4"
      ],
      "metadata": {
        "id": "La_z3nWr40ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "import openai\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2,temperature=0.7, max_tokens=1024)\n",
        "prompt_template_names=\"generate some sweet and unique 10 baby girl {names} from India?\"\n",
        "prompt = PromptTemplate(input_variables=[\"names\"], template=prompt_template_names)\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain_1 = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain_1.run('name'))"
      ],
      "metadata": {
        "id": "h7E3V5EWoyUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31df48b2-5e0a-4bdc-fdec-538f52e7f4f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Aaradhya \n",
            "2. Aanya \n",
            "3. Aarini \n",
            "4. Saira \n",
            "5. Anaya \n",
            "6. Diya \n",
            "7. Anvi \n",
            "8. Aahana \n",
            "9. Keerthi \n",
            "10. Saanvi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question:5"
      ],
      "metadata": {
        "id": "xgZuTbNl46yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2,temperature=0.5, max_tokens=1024)\n",
        "prompt_template_bio=\"Create a made up biography of {names} from {origin}\"\n",
        "prompt_2 = PromptTemplate(input_variables=[\"names\", \"origin\"], template=prompt_template_bio)\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
        "\n",
        "print(chain_2.run({\"names\":\"Aarya\",\"origin\":\"Greece\"}))\n"
      ],
      "metadata": {
        "id": "jZoBSUWZKpDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba848de9-b62a-4745-cc58-16b5c56cc78f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Aarya is a young woman from Greece who is passionate about exploring the world and learning new things. She was born in Athens and grew up in a small village outside the city. As a child, she loved to explore the nearby mountains and forests, and was fascinated by the ancient ruins nearby.\n",
            "\n",
            "At the age of 15, Aarya decided to leave her home and travel the world. She spent the next few years visiting different countries and learning about different cultures. She was particularly interested in the history and culture of Greece, and she spent a lot of time exploring the ancient ruins and learning about the mythology of the country.\n",
            "\n",
            "Aarya eventually decided to settle down in Athens and pursue her studies. She earned a degree in archaeology and went on to become a successful archaeologist. She is now a professor at the University of Athens and has written several books on the history and culture of Greece.\n",
            "\n",
            "Aarya loves to travel and explore new places, and she has visited many countries around the world. She also loves to spend time with her family and friends, and she is an active member of her local community. Aarya is passionate about preserving the history and culture of Greece, and she is always eager to share her knowledge and experiences with others.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.base import Chain\n",
        "\n",
        "from typing import Dict, List\n",
        "\n",
        "\n",
        "class ConcatenateChain(Chain):\n",
        "    chain_1: LLMChain\n",
        "    chain_2: LLMChain\n",
        "\n",
        "    @property\n",
        "    def input_keys(self) -> List[str]:\n",
        "        # Union of the input keys of the two chains.\n",
        "        all_input_vars = set(self.chain_1.input_keys)\n",
        "        return list(all_input_vars)\n",
        "\n",
        "    @property\n",
        "    def output_keys(self) -> Dict[str, str]:\n",
        "        return ['concat_output']\n",
        "\n",
        "    # def _call(self, inputs1: List[str],  inputs2: Dict[str, str]) -> Dict[str, str]:\n",
        "    def _call(self, inputs1: List[str]) -> Dict[str, str]:      \n",
        "        output = self.chain_1.run(inputs1)\n",
        "        return {'concat_output': output }\n",
        "\n",
        "concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)\n",
        "concat_output = concat_chain.run(concat_chain)\n",
        "print(f\"Concatenated output:\\n{concat_output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWckNwNZEc6Z",
        "outputId": "eeb56481-f92c-4caa-f187-3a2a50fa224e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concatenated output:\n",
            "\n",
            "\n",
            "1. Aanya: Born in the heart of India, Aanya was a sweet and unique baby girl with an adventurous spirit. With her bright eyes and infectious smile, Aanya quickly won the hearts of everyone she met. She loved exploring her surroundings and was always curious about the world.\n",
            "\n",
            "2. Anika: Anika was a beautiful baby girl from India with a unique and sweet personality. She had an infectious laugh and a bright, inquisitive mind. She was a natural leader and loved to be in the center of any activity.\n",
            "\n",
            "3. Kavya: Kavya was a sweet and unique baby girl from India who was always full of energy. She was always curious and eager to learn, and she loved to explore her surroundings. She was a happy and adventurous spirit who won the hearts of everyone she met.\n",
            "\n",
            "4. Priya: Priya was a beautiful and unique baby girl from India with a sweet and bubbly personality. She was always curious and loved to explore her surroundings. She had an infectious laugh and a bright, inquisitive mind.\n",
            "\n",
            "5. Riya: Riya was a sweet and unique baby girl from India with a bright and inquisitive mind. She was always full of energy and loved to explore her surroundings. She had an infectious laugh and a bubbly personality that quickly won the hearts of everyone she met.\n",
            "\n",
            "6. Diya: Diya was a sweet and unique baby girl from India with a bright and inquisitive mind. She was always full of energy, and she had an infectious laugh and a bubbly personality that quickly won the hearts of everyone she met.\n",
            "\n",
            "7. Nalini: Nalini was a unique and sweet baby girl from India with an inquisitive and adventurous spirit. She had an infectious laugh and a bright, inquisitive mind. She was a natural leader and loved to be in the center of any activity.\n",
            "\n",
            "8. Maya: Maya was an adventurous and unique baby girl from India with a sweet and bubbly personality. She was always full of energy and loved to explore her surroundings. She had an infectious laugh and a bright, inquisitive mind that quickly won the hearts of everyone she met.\n",
            "\n",
            "9. Samaira: Samaira was a sweet and unique baby girl from India with a bright and inquisitive mind. She was always full of energy and loved to explore her surroundings. She had an infectious laugh and a bubbly personality that quickly won the hearts of everyone she met.\n",
            "\n",
            "10. Ishita: Ishita was a unique and sweet baby girl from India with a bright and inquisitive mind. She was always full of energy and loved to explore her surroundings. She had an infectious laugh and a bubbly personality that quickly won the hearts of everyone she met.\n"
          ]
        }
      ]
    }
  ]
}