{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGf8KTeffm1der0qO6aWZh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreelathagh/NLP/blob/main/LangChain_QUEST2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "ws9Oq20mNPWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f591c36b-856d-4089-c3b6-6336c9fa3c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.8/dist-packages (0.0.81)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.4.46)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.8/dist-packages (from langchain) (3.8.3)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.10.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.21.6)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.8/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.8/dist-packages (from langchain) (2.25.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from langchain) (8.1.0)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.8/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (1.24.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (0.26.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env OPENAI_API_KEY=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"
      ],
      "metadata": {
        "id": "AKrztyEkQNln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de944c4-4749-458b-ef4b-a44f4f791d44"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "mQNXrHFbVEQo"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample Example\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2,temperature=0.8, max_tokens=256)\n",
        "response=llm.generate([\"Tell me a joke.\"])\n",
        "response"
      ],
      "metadata": {
        "id": "1EcGI_QrVJXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7323cc-663a-4ebf-f9bf-7e24f2deaa37"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LLMResult(generations=[[Generation(text='\\n\\nQ: What did the fish say when it swam into the wall? \\nA: Dam!', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nQ. Why did the chicken cross the playground?\\nA. To get to the other slide.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'completion_tokens': 45, 'total_tokens': 50, 'prompt_tokens': 5}})"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question:4"
      ],
      "metadata": {
        "id": "La_z3nWr40ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2,temperature=0.7, max_tokens=1024)\n",
        "prompt_template_names=\"generate some sweet and unique 10 baby girl {name} from India?\"\n",
        "prompt = PromptTemplate(input_variables=[\"name\"], template=prompt_template_names)\n",
        "chain_1 = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "print(chain_1.run('name'))"
      ],
      "metadata": {
        "id": "h7E3V5EWoyUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29aa124a-1e20-4e18-f54f-67e798be6f4e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Aanya\n",
            "2. Aadhya\n",
            "3. Diya\n",
            "4. Archi\n",
            "5. Jiya\n",
            "6. Aashi\n",
            "7. Pari\n",
            "8. Aradhya\n",
            "9. Meera\n",
            "10. Vedika\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question:5"
      ],
      "metadata": {
        "id": "xgZuTbNl46yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name=\"text-davinci-003\",temperature=0.5, max_tokens=1024)\n",
        "prompt_template_bio=\"Create a made up biography of {name} from {origin}\"\n",
        "prompt_2 = PromptTemplate(input_variables=[\"name\", \"origin\"], template=prompt_template_bio)\n",
        "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
        "\n",
        "print(chain_2.run({\"name\":\"Meera\",\"origin\":\"origin\"}))"
      ],
      "metadata": {
        "id": "jZoBSUWZKpDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a671a12c-f821-41d0-de5c-662ca48c36be"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Meera Patel was born in India in 1991 and moved to the United States with her family when she was only five years old. Growing up in a small town in Ohio, she was surrounded by a diverse group of people that helped shape her into the person she is today.\n",
            "\n",
            "Meera was always a bright student, and she excelled in her studies, eventually earning a degree in Computer Science from Ohio State University. After college, she moved to San Francisco to pursue a career in software engineering.\n",
            "\n",
            "In San Francisco, Meera was exposed to a variety of cultures and experiences, which helped her to develop her own unique style and outlook on life. She found a passion for exploring the world and learning about different cultures, and she was always eager to share her knowledge and perspective with others.\n",
            "\n",
            "Meera’s love of travel eventually led her to the world of virtual reality. She was fascinated by the potential of VR to bring people together and allow them to explore new places and experiences. She began to develop her own VR projects, and soon she was creating immersive experiences that allowed people to explore distant lands and experience different cultures.\n",
            "\n",
            "Today, Meera is a successful entrepreneur and VR developer. Her work has been featured in prestigious publications and she is often invited to speak at conferences and events. She continues to explore the world and share her knowledge and experiences with others.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question:6"
      ],
      "metadata": {
        "id": "4Xl64xAj75y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.base import Chain\n",
        "from typing import Dict, List\n",
        "\n",
        "class NameandBio(Chain):\n",
        "    chain_1: LLMChain\n",
        "    chain_2: LLMChain\n",
        "\n",
        "    @property\n",
        "    def input_keys(self) -> List[str]:\n",
        "        all_input_vars = set(self.chain_1.input_keys).union(set(self.chain_2.input_keys))\n",
        "        return list(all_input_vars)\n",
        "\n",
        "    @property\n",
        "    def output_keys(self) -> Dict[str, str]:\n",
        "      return ['Name and Bio']\n",
        "\n",
        "    def _call(self, inputs1: Dict[str, str]) -> List[str]: \n",
        "        output1 = self.chain_1.run(inputs1['name'])\n",
        "        list_nb=[]\n",
        "        for i in range(0,10):\n",
        "          output2 = self.chain_2.run({inputs1['name']:'name',inputs1['origin']:'origin'})\n",
        "          list_nb.append({output2})\n",
        "        return {'Name and Bio': list_nb}\n",
        "\n",
        "concat_chain = NameandBio(chain_1=chain_1, chain_2=chain_2)\n",
        "concat_output = concat_chain.run({'name':'name', 'origin':'origin'})\n",
        "print(\"Baby_name:Biography\", concat_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWckNwNZEc6Z",
        "outputId": "9f1305fc-e0e8-4944-b28c-58f4f8829ff7"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baby_name:Biography [{'\\n\\nJohn Smith:\\nJohn Smith was born in New York City in 1982. He grew up in a loving family, with two younger siblings. His parents were hardworking and instilled a strong work ethic in him from a young age. John excelled in school, and was accepted into an Ivy League university. After graduating, he went on to become a successful businessman, working in finance and investments. He married his college sweetheart and they have two children together. John is an active philanthropist and serves on the board of several charities. He also enjoys playing golf, traveling, and spending time with his family.'}, {'\\n\\nMarcella:\\nMarcella is a passionate and driven woman originally from Mexico. She moved to the United States as a young adult to pursue her dreams of becoming a successful businesswoman. After graduating from college with a degree in business, Marcella quickly found success in the corporate world. She has held a number of positions in various industries, including finance, marketing, and technology.\\n\\nMarcella is an avid traveler and loves to explore new places. She has visited over 20 countries and has a passion for learning about different cultures and customs. She is also a foodie and loves trying new dishes from around the world.\\n\\nMarcella is a dedicated philanthropist and volunteers her time and resources to various causes. She is an advocate for education and is currently working to bring educational resources to underserved communities in Mexico.\\n\\nIn her free time, Marcella enjoys spending time with her family and friends. She also loves to read, take long walks, and practice yoga. Marcella is an inspiring example of what can be achieved when you set your mind to it.'}, {'\\n\\nSophia Díaz:\\nSophia Díaz was born and raised in the Dominican Republic. She was a bright and ambitious child, excelling in school and dreaming of a better future. She moved to the United States at the age of 18 to pursue her dreams of becoming a successful businesswoman. With hard work and determination, she earned a degree in business administration and began working in the corporate world.\\n\\nSophia quickly rose through the ranks and eventually became the president of a large company. She was a natural leader, inspiring her colleagues and motivating them to reach their highest potential. Sophia was also an advocate for diversity and inclusion in the workplace, and she was instrumental in creating a more equitable work environment.\\n\\nThroughout her career, Sophia was a generous philanthropist, donating her time and money to various causes. She was passionate about improving the lives of those around her and worked to create a more equitable society. Sophia was also a strong advocate for education, believing that it was the key to unlocking one’s potential.\\n\\nSophia Díaz was an inspiring leader and a dedicated philanthropist who touched the lives of many. She was a role model for young women everywhere and an example of what can be achieved with hard work and dedication.'}, {'\\n\\nRajesh Patel: Rajesh Patel was born and raised in Gujarat, India. He grew up in a middle-class family, with his parents instilling in him a strong work ethic and a passion for education. After graduating from high school, Rajesh went on to study engineering at the Indian Institute of Technology. He excelled in his studies and was awarded a scholarship to pursue a postgraduate degree at the University of Oxford in the United Kingdom.\\n\\nRajesh moved to the UK and began his studies, eventually earning a doctorate in engineering. After completing his studies, Rajesh decided to stay in the UK, and he began working as an engineer for a large engineering firm. Over the years, Rajesh worked his way up the corporate ladder and eventually became the CEO of the company.\\n\\nThroughout his career, Rajesh was known for his innovative ideas and his ability to think outside the box. He was also passionate about giving back to his community, and he was a major supporter of educational initiatives in India. Rajesh retired from his career in engineering in 2020, and he currently lives in London with his wife and two children.'}, {\"\\n\\nKatherine Smith:\\nKatherine Smith is a native of Chicago, Illinois. She was born and raised in the city and has always been passionate about the arts. She studied theatre at Northwestern University and graduated with a Bachelor's degree in Theatre Arts. After college, she moved to Los Angeles and began her career in the entertainment industry as an actress and writer. She has appeared in a number of films and television shows, and has written for several television series and films. Katherine is also an avid traveler and has visited many countries around the world. She loves to explore different cultures and has a passion for learning about different cultures. In her spare time, Katherine enjoys spending time with her family and friends, reading, and spending time outdoors.\"}, {\"\\n\\nImani Smith:\\nImani Smith was born in Jamaica and immigrated to the United States at the age of 8. Growing up in a small town in Florida, Imani was determined to make a difference in her community. She worked hard in school, eventually graduating from Florida State University with a degree in Political Science. After college, she moved to Washington D.C. and began working for a non-profit organization that focused on helping those in need.\\n\\nImani was passionate about making a difference and quickly rose through the ranks of the organization. She eventually became the Executive Director, leading the organization to new heights. Imani was a strong advocate for social justice and was instrumental in helping to pass several pieces of legislation that benefited those in need.\\n\\nImani's work in Washington D.C. earned her recognition from several prominent politicians and she was even invited to the White House to meet with President Obama. She was also invited to speak at numerous events, including the United Nations General Assembly.\\n\\nToday, Imani continues to work for the non-profit organization, but also serves on several boards and committees. She is a respected leader in her community and is a role model for many young people. Imani's life story is an inspiration to anyone who dreams of making a difference in the world.\"}, {\"\\n\\nAamir Khan:\\nAamir Khan was born in India and raised in Mumbai. He is a renowned actor, director, producer, and philanthropist. He began his career in the entertainment industry in 1988 with the film Qayamat Se Qayamat Tak, and his performance in the film won him a Filmfare Award for Best Male Debut. He has since gone on to star in some of the most successful films in Bollywood, including Dil Chahta Hai, 3 Idiots, and Dangal.\\n\\nIn addition to his film career, Khan is also involved in several charity initiatives. He is the founder of the NGO Paani Foundation, which works to bring water to rural areas of India. He is also a vocal advocate for women's rights and has spoken out against violence against women. He is a strong supporter of education and has donated to various educational charities in India. Khan has been recognized for his work in the entertainment industry and his philanthropic endeavors, receiving numerous awards and accolades.\"}, {'\\n\\nJohn Smith:\\nJohn Smith was born in London, England in 1975. He was raised in a middle-class family and his parents always encouraged him to pursue his dreams. John was an excellent student and always strived to do his best in school. After graduating from high school, John attended college and eventually earned a degree in business.\\n\\nJohn then went on to work in the banking industry, where he quickly rose through the ranks to become a successful executive. He was always eager to learn and take on new challenges, and his hard work and dedication paid off.\\n\\nJohn eventually decided to pursue his entrepreneurial dreams and started his own business. He worked tirelessly to make it a success and eventually became one of the most successful businessmen in the area. He was well respected in the business community and was an inspiration to many.\\n\\nJohn was also an active member of his community and was involved in many charities and organizations. He was a generous man who always put others before himself. John was married and had two children, and he was a loving father who always put his family first.\\n\\nJohn Smith passed away in 2020, leaving behind a legacy of hard work, dedication, and generosity. He will be remembered fondly by all who knew him.'}, {\"\\n\\nJenna Smith:\\nJenna Smith was born and raised in the small town of Middletown, Ohio. She was the youngest of three children and had a passion for learning from a young age. She graduated from Middletown High School at the top of her class and went on to attend Ohio State University. Jenna was a bright and ambitious student, and she graduated with honors in three years.\\n\\nAfter college, Jenna moved to New York City to pursue her dream of becoming a successful businesswoman. She quickly found success in the corporate world and worked her way up the ladder at an investment firm. Jenna was a hard worker and was quickly promoted to a managerial position.\\n\\nJenna eventually decided to start her own business. She opened a boutique clothing store in the heart of Manhattan and it quickly became a success. Jenna's business acumen and keen eye for fashion soon made her a well-known figure in the fashion industry.\\n\\nToday, Jenna continues to run her business with success. She is an inspiration to many and a role model for women everywhere. Jenna is a living example of how hard work and dedication can lead to success.\"}, {'\\n\\nNina Smith:\\nNina Smith is a native of Los Angeles, California. She grew up in a large family with five siblings, and was always interested in the arts. She attended a prestigious art school and went on to pursue a career in graphic design. After college, Nina moved to New York City and quickly made a name for herself in the design world. She worked with some of the biggest names in the industry, and her designs were featured in major publications.\\n\\nNina is an incredibly talented designer, but she is also passionate about giving back to her community. She volunteers her time and resources to help those in need, and she is an active member of several charities. Her philanthropic efforts have earned her the respect of her peers, and she continues to use her creativity to make the world a better place.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1_1oPRNSW7QWdlUs-APMV5Y7h6RxU_8gF')\n",
        "with open('cs.cl.sample100.json') as f:\n",
        "    data = f.readlines()\n",
        "parsed = [json.loads(x) for x in data]\n",
        "sample10 = random.choices(parsed, k=10)\n",
        "\n",
        "titles=[]\n",
        "abstracts=[]\n",
        "for i in range(0,10):\n",
        "  titles.append(sample10[i]['title'])\n",
        "  abstracts.append(sample10[i]['abstract'])\n",
        "\n",
        "prompt_template_arxiv=\"Create a summary as why Should I read this paper from ArXiv with {title} using this {abstract}\"\n",
        "prompt_3 = PromptTemplate(input_variables=[\"title\", \"abstract\"], template=prompt_template_arxiv)\n",
        "chain_3 = LLMChain(llm=llm, prompt=prompt_3)\n",
        "\n",
        "for i in range(0,10):\n",
        "  print(\"\\n\")\n",
        "  print(\"*\", titles[i],\":\", chain_3.run({\"title\":titles[i],\"abstract\":abstracts[i].replace('\\n','')}))\n",
        "  # print(chain_3.run({\"title\":titles[i],\"abstract\":abstracts[i].replace('\\n','')}))"
      ],
      "metadata": {
        "id": "-wV1yokC74pU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e87e5ab-1160-43e8-ac34-8a8d4a8ff0a5"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_1oPRNSW7QWdlUs-APMV5Y7h6RxU_8gF\n",
            "To: /content/cs.cl.sample100.json\n",
            "100%|██████████| 135k/135k [00:00<00:00, 64.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "* Verbal chunk extraction in French using limited resources : \n",
            "\n",
            "This paper explores a system for extracting French verbal chunks using limited resources. It outlines the specific goals, architecture and formalism of the system, and presents the results of applying it to an effective corpus. It relies on declarative morphological and local grammar rules, as well as some simple heuristic and statistic properties obtained from restricted corpora. Reading this paper provides insight into how a system can extract French verbal chunks from limited resources.\n",
            "\n",
            "\n",
            "* Question Answering System Using Syntactic Information : \n",
            "\n",
            "This paper explores the use of syntactic information to develop a question answering system for Japanese sentences. The paper examines the effectiveness of using syntactic information to select the correct answer from knowledge-based data written in natural language. This technique can provide more accurate answers than those currently being used in TREC8 for English documents. Reading this paper will help you understand how syntactic information can be used to improve the accuracy of question answering systems.\n",
            "\n",
            "\n",
            "* Selective Sampling for Example-based Word Sense Disambiguation : \n",
            "\n",
            "This paper is a great read for anyone interested in example-based Word Sense Disambiguation. It proposes a selective sampling method which reduces the manual sense disambiguation overhead and improves the search time complexity by creating a smaller and more effective example set. The paper also reports the effectiveness of the method in experiments on one thousand sentences, showing that the performance of the system is not degraded. This paper is thus highly relevant and informative for anyone looking to improve their Word Sense Disambiguation systems.\n",
            "\n",
            "\n",
            "* Expoiting Syntactic Structure for Language Modeling : \n",
            "\n",
            "This paper discusses an innovative language model that exploits syntactic structure to extract meaningful information from the word history. The model assigns a probability to each sequence of words, operating in a left-to-right manner, and is suitable for automatic speech recognition. Experiments to evaluate the model's predictive power are presented and demonstrate an improvement over standard trigram modeling. Readers interested in language modeling, syntactic structure, and automatic speech recognition will find this paper relevant.\n",
            "\n",
            "\n",
            "* An electronic dictionary as a basis for NLP tools: The Greek case :  \n",
            "\n",
            "This paper discusses the importance of an electronic dictionary for Modern Greek and how it is necessary to use this dictionary to create efficient and sophisticated NLP applications. It outlines the two-phase process of constructing the dictionary to build a spelling correction schema and then to deploy a wider range of NLP tools. Readers should read this paper to understand the significance of an electronic dictionary for NLP applications and to learn about the two-phase process of constructing it.\n",
            "\n",
            "\n",
            "* Restrictions on Tree Adjoining Languages : \n",
            "\n",
            "This paper is perfect for those interested in exploring the complexities of languages generated by Tree Adjoining Grammars (TAGs). It outlines several methods for parsing such languages in O(n^6) worst case running time, and investigates which restrictions on TAGs and TAG derivations are necessary in order to lower this time complexity without sacrificing any of the generative power needed to capture the syntactic constructions in natural language. It also describes an algorithm for parsing a strict subclass of TAG in O(n^5) and attempts to prove that this subclass still has enough generative power to be applicable in the general case. Reading this paper is an essential step for anyone interested in comprehending TAGs and how to parse them effectively.\n",
            "\n",
            "\n",
            "* Architectural Considerations for Conversational Systems -- The\n",
            "  Verbmobil/INTARC Experience : \n",
            "\n",
            "This paper provides an important insight into the design and development of conversational systems. It outlines the general design goals and considerations of the INTARC system architecture and its subsequent application in the Verbmobil project. The paper also provides an in-depth description of the engineering approach used to construct INTARC 2.0, which includes the integration of symbolic and stochastic techniques. This paper is particularly beneficial to those interested in understanding the complexities involved in the development of conversational systems, as well as those looking for case studies of how these systems are put together.\n",
            "\n",
            "\n",
            "* Effects of Language Modeling on Speech-driven Question Answering : \n",
            "\n",
            "This paper explores the application of language modeling to speech-driven question answering. It evaluates the performance of such a system by adapting an N-gram language model to natural language questions and producing a general N-gram model. The proposed passage retrieval method is robust against recognition errors in the transcription. Results from experiments on the QA test collection produced in NTCIR are presented, demonstrating the effectiveness of the proposed method. Readers interested in speech-driven question answering should read this paper to learn more about the use of language modeling.\n",
            "\n",
            "\n",
            "* Resolution of Indirect Anaphora in Japanese Sentences Using Examples 'X\n",
            "  no Y (Y of X)' : \n",
            "\n",
            "This paper provides a novel approach to resolving indirect anaphora in Japanese sentences using examples of \"X no Y\" (Y of X). The approach was evaluated on test sentences and was found to have a recall rate of 63% and a precision rate of 68%. Furthermore, the paper proposes a way to construct a noun case frame dictionary by using examples of \"X no Y\". Reading this paper is useful for anyone interested in natural language processing, language understanding, and machine translation.\n",
            "\n",
            "\n",
            "* Prefix Probabilities from Stochastic Tree Adjoining Grammars : \n",
            "\n",
            "This paper presents a new algorithm for computing prefix probabilities given a stochastic Tree Adjoining Grammar. The algorithm achieves the required computation in O(n^6) time, while also taking into account the probability of subderivations that do not derive any words in the prefix. This allows existing corpus-based estimation techniques to be used for language modelling. Therefore, readers interested in language modelling and natural language processing should read this paper to understand the algorithm and its implications for the field.\n"
          ]
        }
      ]
    }
  ]
}